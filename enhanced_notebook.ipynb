{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Comprehensive Movie Data Analysis & Extraction System\n",
    "\n",
    "## Overview\n",
    "This notebook provides a complete system for:\n",
    "- Listing Tamil movies from Moviesda\n",
    "- Searching for specific movies\n",
    "- Extracting detailed movie information\n",
    "- Analyzing movie metadata\n",
    "- Downloading and organizing movie data\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Enhanced Movie Analysis System  \n",
    "**Version:** 2.0  \n",
    "**Last Updated:** January 2026\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Table of Contents\n",
    "\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [Import Libraries](#imports)\n",
    "3. [Configuration](#config)\n",
    "4. [Core Functions](#functions)\n",
    "5. [Movie Listing](#listing)\n",
    "6. [Movie Search](#search)\n",
    "7. [Detailed Movie Information](#details)\n",
    "8. [Data Analysis](#analysis)\n",
    "9. [Export & Save](#export)\n",
    "10. [Advanced Features](#advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Installation <a id='setup'></a>\n",
    "\n",
    "Install all required packages for the movie data extraction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install requests beautifulsoup4 pandas numpy matplotlib seaborn lxml --quiet\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Import Libraries <a id='imports'></a>\n",
    "\n",
    "Import all necessary libraries for data extraction, processing, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File operations\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÖ Current Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Configuration <a id='config'></a>\n",
    "\n",
    "Configure the system parameters and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Class\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the movie extraction system\"\"\"\n",
    "    \n",
    "    # Base URLs\n",
    "    BASE_URL = \"https://moviesda15.com\"\n",
    "    \n",
    "    # Headers for requests\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    \n",
    "    # Request settings\n",
    "    TIMEOUT = 30\n",
    "    MAX_RETRIES = 3\n",
    "    RETRY_DELAY = 2\n",
    "    \n",
    "    # Data directories\n",
    "    DATA_DIR = Path('/mnt/user-data/outputs')\n",
    "    CACHE_DIR = Path('/home/claude/cache')\n",
    "    \n",
    "    # Default year\n",
    "    DEFAULT_YEAR = '2026'\n",
    "    \n",
    "    @classmethod\n",
    "    def create_directories(cls):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        cls.DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        cls.CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"‚úÖ Created directories: {cls.DATA_DIR}, {cls.CACHE_DIR}\")\n",
    "\n",
    "# Initialize configuration\n",
    "Config.create_directories()\n",
    "print(\"‚úÖ Configuration initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Core Functions <a id='functions'></a>\n",
    "\n",
    "Define all core functions for movie data extraction and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieExtractor:\n",
    "    \"\"\"Main class for extracting movie data from Moviesda\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(Config.HEADERS)\n",
    "    \n",
    "    def make_request(self, url: str, retries: int = Config.MAX_RETRIES) -> Optional[requests.Response]:\n",
    "        \"\"\"\n",
    "        Make an HTTP request with retry logic\n",
    "        \n",
    "        Args:\n",
    "            url: URL to fetch\n",
    "            retries: Number of retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            Response object or None if failed\n",
    "        \"\"\"\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = self.session.get(url, timeout=Config.TIMEOUT)\n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"‚ö†Ô∏è Attempt {attempt + 1}/{retries} failed: {e}\")\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(Config.RETRY_DELAY)\n",
    "                else:\n",
    "                    print(f\"‚ùå Failed to fetch {url} after {retries} attempts\")\n",
    "                    return None\n",
    "    \n",
    "    def list_movies(self, year: str = Config.DEFAULT_YEAR) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        List all movies for a specific year\n",
    "        \n",
    "        Args:\n",
    "            year: Year to fetch movies for\n",
    "            \n",
    "        Returns:\n",
    "            List of movie dictionaries\n",
    "        \"\"\"\n",
    "        print(f\"\\nüé¨ Fetching movies for year: {year}\")\n",
    "        url = f\"{Config.BASE_URL}/year/{year}/\"\n",
    "        \n",
    "        response = self.make_request(url)\n",
    "        if not response:\n",
    "            return []\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        movies = []\n",
    "        \n",
    "        # Find all movie articles\n",
    "        articles = soup.find_all('article', class_='item movies')\n",
    "        \n",
    "        for article in articles:\n",
    "            try:\n",
    "                # Extract movie data\n",
    "                title_tag = article.find('h3')\n",
    "                link_tag = article.find('a', href=True)\n",
    "                img_tag = article.find('img')\n",
    "                \n",
    "                if title_tag and link_tag:\n",
    "                    movie_data = {\n",
    "                        'title': title_tag.get_text(strip=True),\n",
    "                        'url': link_tag['href'],\n",
    "                        'year': year,\n",
    "                        'poster': img_tag['src'] if img_tag and 'src' in img_tag.attrs else None,\n",
    "                        'type': 'movie'  # Can be enhanced to detect web-series\n",
    "                    }\n",
    "                    movies.append(movie_data)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error parsing movie: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(movies)} movies for {year}\")\n",
    "        return movies\n",
    "    \n",
    "    def get_movie_details(self, movie_url: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract detailed information about a movie\n",
    "        \n",
    "        Args:\n",
    "            movie_url: URL of the movie page\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with comprehensive movie details\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîç Fetching details from: {movie_url}\")\n",
    "        \n",
    "        response = self.make_request(movie_url)\n",
    "        if not response:\n",
    "            return {}\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        details = {'url': movie_url}\n",
    "        \n",
    "        # Extract title\n",
    "        title_tag = soup.find('h1', class_='entry-title')\n",
    "        if title_tag:\n",
    "            details['title'] = title_tag.get_text(strip=True)\n",
    "        \n",
    "        # Extract metadata\n",
    "        meta_items = soup.find_all('div', class_='sgeneros')\n",
    "        for item in meta_items:\n",
    "            text = item.get_text(strip=True)\n",
    "            if 'Genre:' in text:\n",
    "                details['genre'] = text.replace('Genre:', '').strip()\n",
    "            elif 'Year:' in text:\n",
    "                details['year'] = text.replace('Year:', '').strip()\n",
    "        \n",
    "        # Extract plot/description\n",
    "        plot_div = soup.find('div', class_='wp-content')\n",
    "        if plot_div:\n",
    "            details['plot'] = plot_div.get_text(strip=True)\n",
    "        \n",
    "        # Extract poster\n",
    "        poster_img = soup.find('div', class_='poster').find('img') if soup.find('div', class_='poster') else None\n",
    "        if poster_img and 'src' in poster_img.attrs:\n",
    "            details['poster'] = poster_img['src']\n",
    "        \n",
    "        # Extract download links\n",
    "        details['download_links'] = self._extract_download_links(soup)\n",
    "        \n",
    "        # Extract cast and crew\n",
    "        details['cast'] = self._extract_cast_crew(soup)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully extracted details for: {details.get('title', 'Unknown')}\")\n",
    "        return details\n",
    "    \n",
    "    def _extract_download_links(self, soup: BeautifulSoup) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract all download links from movie page\n",
    "        \n",
    "        Args:\n",
    "            soup: BeautifulSoup object of the page\n",
    "            \n",
    "        Returns:\n",
    "            List of download link dictionaries\n",
    "        \"\"\"\n",
    "        links = []\n",
    "        \n",
    "        # Find all download sections\n",
    "        download_sections = soup.find_all('div', class_='download-links')\n",
    "        \n",
    "        for section in download_sections:\n",
    "            quality_tags = section.find_all('a', href=True)\n",
    "            \n",
    "            for tag in quality_tags:\n",
    "                link_data = {\n",
    "                    'url': tag['href'],\n",
    "                    'text': tag.get_text(strip=True),\n",
    "                    'quality': self._extract_quality(tag.get_text(strip=True))\n",
    "                }\n",
    "                links.append(link_data)\n",
    "        \n",
    "        return links\n",
    "    \n",
    "    def _extract_quality(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract quality information from link text\n",
    "        \n",
    "        Args:\n",
    "            text: Link text\n",
    "            \n",
    "        Returns:\n",
    "            Quality string (480p, 720p, 1080p, etc.)\n",
    "        \"\"\"\n",
    "        quality_patterns = ['480p', '720p', '1080p', '4K', '2K']\n",
    "        for pattern in quality_patterns:\n",
    "            if pattern.lower() in text.lower():\n",
    "                return pattern\n",
    "        return 'Unknown'\n",
    "    \n",
    "    def _extract_cast_crew(self, soup: BeautifulSoup) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract cast and crew information\n",
    "        \n",
    "        Args:\n",
    "            soup: BeautifulSoup object of the page\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with cast and crew details\n",
    "        \"\"\"\n",
    "        cast_crew = {}\n",
    "        \n",
    "        # Find cast/crew section\n",
    "        cast_section = soup.find('div', class_='persons')\n",
    "        \n",
    "        if cast_section:\n",
    "            items = cast_section.find_all('div', class_='person')\n",
    "            \n",
    "            for item in items:\n",
    "                role = item.find('span', class_='role')\n",
    "                name = item.find('span', class_='name')\n",
    "                \n",
    "                if role and name:\n",
    "                    role_text = role.get_text(strip=True)\n",
    "                    name_text = name.get_text(strip=True)\n",
    "                    cast_crew[role_text] = name_text\n",
    "        \n",
    "        return cast_crew\n",
    "    \n",
    "    def search_movie(self, title: str, year: str = Config.DEFAULT_YEAR) -> Dict:\n",
    "        \"\"\"\n",
    "        Search for a movie by title\n",
    "        \n",
    "        Args:\n",
    "            title: Movie title to search for\n",
    "            year: Year to search in\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with search results and details\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîç Searching for: '{title}' in year {year}\")\n",
    "        \n",
    "        # List all movies for the year\n",
    "        all_movies = self.list_movies(year)\n",
    "        \n",
    "        # Search for matching titles\n",
    "        matches = [\n",
    "            movie for movie in all_movies \n",
    "            if title.lower() in movie['title'].lower()\n",
    "        ]\n",
    "        \n",
    "        if not matches:\n",
    "            print(f\"‚ùå No movies found matching '{title}'\")\n",
    "            return {'matches': [], 'total': 0}\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(matches)} matching movie(s)\")\n",
    "        \n",
    "        # Get details for the best match\n",
    "        best_match = matches[0]\n",
    "        details = self.get_movie_details(best_match['url'])\n",
    "        \n",
    "        return {\n",
    "            'matches': matches,\n",
    "            'total': len(matches),\n",
    "            'best_match': best_match,\n",
    "            'details': details\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Core functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Movie Listing <a id='listing'></a>\n",
    "\n",
    "List all available movies for a specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the extractor\n",
    "extractor = MovieExtractor()\n",
    "\n",
    "# List movies for 2026\n",
    "year_to_search = '2026'\n",
    "movies_2026 = extractor.list_movies(year_to_search)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df_movies = pd.DataFrame(movies_2026)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìä Total Movies Found: {len(df_movies)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MOVIE LIST:\")\n",
    "print(\"=\"*80)\n",
    "display(df_movies.head(20))\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = Config.DATA_DIR / f'movies_{year_to_search}.csv'\n",
    "df_movies.to_csv(csv_path, index=False)\n",
    "print(f\"\\nüíæ Saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Movie Search <a id='search'></a>\n",
    "\n",
    "Search for specific movies by title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a specific movie\n",
    "search_title = \"Parasakthi\"  # Change this to search for different movies\n",
    "search_year = \"2026\"\n",
    "\n",
    "search_results = extractor.search_movie(search_title, search_year)\n",
    "\n",
    "# Display search results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SEARCH RESULTS FOR: '{search_title}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if search_results['total'] > 0:\n",
    "    print(f\"\\n‚úÖ Found {search_results['total']} matching movie(s):\\n\")\n",
    "    \n",
    "    for i, match in enumerate(search_results['matches'], 1):\n",
    "        print(f\"{i}. {match['title']}\")\n",
    "        print(f\"   URL: {match['url']}\")\n",
    "        print(f\"   Year: {match['year']}\\n\")\n",
    "    \n",
    "    # Display detailed information\n",
    "    if 'details' in search_results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DETAILED INFORMATION:\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        details = search_results['details']\n",
    "        for key, value in details.items():\n",
    "            if key not in ['download_links', 'cast']:\n",
    "                print(f\"\\n{key.upper()}: {value}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå No movies found matching '{search_title}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Detailed Movie Information <a id='details'></a>\n",
    "\n",
    "Extract comprehensive details about a specific movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details for a specific movie URL\n",
    "# Replace with actual movie URL from the search results\n",
    "if search_results['total'] > 0:\n",
    "    movie_url = search_results['best_match']['url']\n",
    "    \n",
    "    # Extract detailed information\n",
    "    movie_details = extractor.get_movie_details(movie_url)\n",
    "    \n",
    "    # Display comprehensive details\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE MOVIE DETAILS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüé¨ Title: {movie_details.get('title', 'N/A')}\")\n",
    "    print(f\"üìÖ Year: {movie_details.get('year', 'N/A')}\")\n",
    "    print(f\"üé≠ Genre: {movie_details.get('genre', 'N/A')}\")\n",
    "    print(f\"üîó URL: {movie_details.get('url', 'N/A')}\")\n",
    "    \n",
    "    if 'plot' in movie_details:\n",
    "        print(f\"\\nüìñ Plot:\\n{movie_details['plot'][:500]}...\")\n",
    "    \n",
    "    if 'cast' in movie_details and movie_details['cast']:\n",
    "        print(\"\\nüë• Cast & Crew:\")\n",
    "        for role, name in movie_details['cast'].items():\n",
    "            print(f\"   {role}: {name}\")\n",
    "    \n",
    "    if 'download_links' in movie_details and movie_details['download_links']:\n",
    "        print(f\"\\nüíæ Download Links ({len(movie_details['download_links'])} available):\")\n",
    "        for i, link in enumerate(movie_details['download_links'][:5], 1):\n",
    "            print(f\"   {i}. {link['text']} - Quality: {link['quality']}\")\n",
    "    \n",
    "    # Save detailed information to JSON\n",
    "    json_path = Config.DATA_DIR / f\"movie_details_{movie_details.get('title', 'unknown').replace(' ', '_')}.json\"\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(movie_details, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Detailed information saved to: {json_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No movie selected for detailed extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Data Analysis <a id='analysis'></a>\n",
    "\n",
    "Analyze the collected movie data with visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze movie data\n",
    "if len(df_movies) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìä Total Movies: {len(df_movies)}\")\n",
    "    print(f\"üìä Unique Years: {df_movies['year'].nunique()}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Movie Data Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Movies by Type\n",
    "    if 'type' in df_movies.columns:\n",
    "        df_movies['type'].value_counts().plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "        axes[0, 0].set_title('Movies by Type')\n",
    "        axes[0, 0].set_xlabel('Type')\n",
    "        axes[0, 0].set_ylabel('Count')\n",
    "    \n",
    "    # 2. Top 10 Movies (by title length - just for demonstration)\n",
    "    df_movies['title_length'] = df_movies['title'].str.len()\n",
    "    top_movies = df_movies.nlargest(10, 'title_length')[['title', 'title_length']]\n",
    "    axes[0, 1].barh(range(len(top_movies)), top_movies['title_length'], color='lightcoral')\n",
    "    axes[0, 1].set_yticks(range(len(top_movies)))\n",
    "    axes[0, 1].set_yticklabels(top_movies['title'], fontsize=8)\n",
    "    axes[0, 1].set_title('Top 10 Movies by Title Length')\n",
    "    axes[0, 1].set_xlabel('Title Length')\n",
    "    \n",
    "    # 3. Movies distribution\n",
    "    axes[1, 0].hist(df_movies['title_length'], bins=20, color='lightgreen', edgecolor='black')\n",
    "    axes[1, 0].set_title('Distribution of Title Lengths')\n",
    "    axes[1, 0].set_xlabel('Title Length')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 4. Summary statistics\n",
    "    stats_text = f\"\"\"Summary Statistics:\n",
    "    \n",
    "Total Movies: {len(df_movies)}\n",
    "Average Title Length: {df_movies['title_length'].mean():.1f}\n",
    "Median Title Length: {df_movies['title_length'].median():.1f}\n",
    "Shortest Title: {df_movies['title_length'].min()}\n",
    "Longest Title: {df_movies['title_length'].max()}\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center')\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].set_title('Statistics Overview')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_path = Config.DATA_DIR / 'movie_analysis.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nüìä Analysis plot saved to: {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Export & Save <a id='export'></a>\n",
    "\n",
    "Export all collected data in various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data in multiple formats\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(df_movies) > 0:\n",
    "    # 1. CSV Export\n",
    "    csv_file = Config.DATA_DIR / f'movies_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "    df_movies.to_csv(csv_file, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ CSV exported to: {csv_file}\")\n",
    "    \n",
    "    # 2. Excel Export\n",
    "    try:\n",
    "        excel_file = Config.DATA_DIR / f'movies_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
    "        df_movies.to_excel(excel_file, index=False, engine='openpyxl')\n",
    "        print(f\"‚úÖ Excel exported to: {excel_file}\")\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è openpyxl not installed. Skipping Excel export.\")\n",
    "    \n",
    "    # 3. JSON Export\n",
    "    json_file = Config.DATA_DIR / f'movies_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "    df_movies.to_json(json_file, orient='records', indent=2, force_ascii=False)\n",
    "    print(f\"‚úÖ JSON exported to: {json_file}\")\n",
    "    \n",
    "    # 4. HTML Report\n",
    "    html_file = Config.DATA_DIR / f'movies_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.html'\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Movie Data Report</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "            h1 {{ color: #333; }}\n",
    "            table {{ border-collapse: collapse; width: 100%; }}\n",
    "            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "            th {{ background-color: #4CAF50; color: white; }}\n",
    "            tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Movie Data Report - {datetime.now().strftime('%Y-%m-%d')}</h1>\n",
    "        <p>Total Movies: {len(df_movies)}</p>\n",
    "        {df_movies.to_html(index=False, escape=False)}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    with open(html_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    print(f\"‚úÖ HTML report exported to: {html_file}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All exports completed successfully!\")\n",
    "    print(f\"üìÅ Files saved to: {Config.DATA_DIR}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Advanced Features <a id='advanced'></a>\n",
    "\n",
    "Advanced functionality for batch processing and automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process multiple movies\n",
    "def batch_extract_movies(movie_urls: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract details for multiple movies at once\n",
    "    \n",
    "    Args:\n",
    "        movie_urls: List of movie URLs\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all movie details\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ Batch extracting {len(movie_urls)} movies...\")\n",
    "    \n",
    "    all_details = []\n",
    "    \n",
    "    for i, url in enumerate(movie_urls, 1):\n",
    "        print(f\"\\nProcessing {i}/{len(movie_urls)}: {url}\")\n",
    "        details = extractor.get_movie_details(url)\n",
    "        if details:\n",
    "            all_details.append(details)\n",
    "        time.sleep(1)  # Be respectful to the server\n",
    "    \n",
    "    df = pd.DataFrame(all_details)\n",
    "    print(f\"\\n‚úÖ Batch extraction complete! Extracted {len(df)} movies.\")\n",
    "    return df\n",
    "\n",
    "# Example: Extract details for top 5 movies\n",
    "if len(df_movies) > 0:\n",
    "    top_5_urls = df_movies['url'].head(5).tolist()\n",
    "    batch_results = batch_extract_movies(top_5_urls)\n",
    "    \n",
    "    # Display batch results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BATCH EXTRACTION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    display(batch_results[['title', 'year', 'genre']].head())\n",
    "    \n",
    "    # Save batch results\n",
    "    batch_file = Config.DATA_DIR / f'batch_extraction_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "    batch_results.to_csv(batch_file, index=False)\n",
    "    print(f\"\\nüíæ Batch results saved to: {batch_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "This notebook provides a complete system for:\n",
    "\n",
    "- ‚úÖ Listing movies by year\n",
    "- ‚úÖ Searching for specific movies\n",
    "- ‚úÖ Extracting comprehensive movie details\n",
    "- ‚úÖ Analyzing movie data\n",
    "- ‚úÖ Exporting data in multiple formats\n",
    "- ‚úÖ Batch processing multiple movies\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Customize search parameters\n",
    "2. Add more analysis features\n",
    "3. Implement caching for faster performance\n",
    "4. Add error handling for edge cases\n",
    "5. Create automated reports\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Movie Hunting! üé¨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
